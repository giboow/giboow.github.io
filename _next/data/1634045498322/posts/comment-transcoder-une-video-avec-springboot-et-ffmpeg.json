{"pageProps":{"postData":{"id":"comment-transcoder-une-video-avec-springboot-et-ffmpeg","contentHtml":"<p>J'ai récemment commencé à travailler sur un système de caméras de surveillance et je souhaite pouvoir afficher les vidéos collectées sur des pages Web.\nÀ première vue, cela semblait très facile, mais je me suis vite rendu compte que je devais me creuser la tête!</p>\n<h1>Comment cela doit fonctionner?</h1>\n<p>La caméra est connectée à un NVR (Numeric Video recorder) qui possède une API permettant de récupérer les informations de configuration et le flux vidéo. En cherchant un peu sur le Web (Oui la documentation est difficile d'accès..), je découvre que le protocole de communication utilisé par le NVR est le RTSP (Real-Time Streaming Protocol). C'est là que je rencontre le principal problème ! Comment utiliser ce protocole dans une page HTML qui ne le supporte pas ? Ma solution est d'utiliser un serveur qui permet de transcoder la vidéo dans un format plus connu (MP4) et un protocole ultra standard (Http). Cela me permettra également de cacher les identifiants d'accès à la caméra en utilisant mon serveur comme un proxy.</p>\n<p><img src=\"https://giboow.fr/static/images/post/proxy-transcoder-ffmpeg/graph-ffmpeg-transcoder.png\" alt=\"Graph it should work\"></p>\n<h1>Alors comment on fait ça?</h1>\n<p>Un excellent outil bien connu pour faire de la conversion vidéo est <a href=\"https://www.ffmpeg.org/\">FFMPeg</a>, donc je commence à regarder comment je peux l'utiliser pour convertir RSTP. Je trouve rapidement une ligne de commande qui fonctionne :</p>\n<pre><code class=\"language-bash\">ffmpeg -y -loglevel level+info -n -re -acodec pcm_s16le -rtsp_transport tcp -i rtsp://user:passwd@192.168.1.200:554/ISAPI/Streaming/channels/101/live -vcodec copy -af asetrate=22050 -acodec aac -b:a 96k -nostdin myvideo.mp4\n</code></pre>\n<p>Alors comment faire un proxy avec SpringBoot ? C'est très simple en fait, il suffit d'utiliser l'objet <a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/servlet/mvc/method/annotation/StreamingResponseBody.html\">StreamingResponseBody</a>. Cela permet de renvoyer un traitement asynchrone de la requête, où l'application peut écrire directement sur le flux de sortie de la réponse sans bloquer le reste de mon API.</p>\n<p>Enfin, il me suffit d'utiliser FFMPEG dans mon contrôleur pour envoyer le flux via mon API. J'aurais pu utiliser \" Runtime.getRuntime().exec(\" ffmpeg...) \" mais je n'arrivais pas à trouver comment obtenir mon flux. Heureusement, j'ai trouvé une bibliothèque magique <a href=\"https://github.com/kokorin/Jaffree\">Jaffree</a> : \"Jaffree stands for JAva FFmpeg and FFprobe FREE command line wrapper. Jaffree supports programmatic video production and consumption (with transparency)\"</p>\n<h1>La solution</h1>\n<p>Voici la solution finale et comment relayer un flux vidéo provenant d'une caméra HikVision afin que le format soit utilisable par une page HTML.</p>\n<pre><code class=\"language-java\">@RestController\n@RequestMapping(\"/video\")\n@Log4j2\npublic class VideoController {\n\t\t@GetMapping(value = \"/live.mp4\")\n    @ResponseBody\n    public ResponseEntity&#x3C;StreamingResponseBody> livestream(@PathVariable(\"id\") Long tipperId) throws Exception {\n\n\t\t\t\tString rtspUrl = \"rtsp://user:passwd@192.168.1.200:554/ISAPI/Streaming/channels/101/live\";\n\n        return ResponseEntity.ok()\n                .contentType(MediaType.APPLICATION_OCTET_STREAM)\n                .body(os -> {\n                    FFmpeg.atPath()\n                            .addArgument(\"-re\")\n                            .addArguments(\"-acodec\", \"pcm_s16le\")\n                            .addArguments(\"-rtsp_transport\", \"tcp\")\n                            .addArguments(\"-i\", $rtspUrl)\n                            .addArguments(\"-vcodec\", \"copy\")\n                            .addArguments(\"-af\", \"asetrate=22050\")\n                            .addArguments(\"-acodec\", \"aac\")\n                            .addArguments(\"-b:a\", \"96k\" )\n                            .addOutput(PipeOutput.pumpTo(os)\n                                    .disableStream(StreamType.AUDIO)\n                                    .disableStream(StreamType.SUBTITLE)\n                                    .disableStream(StreamType.DATA)\n                                    .setFrameCount(StreamType.VIDEO, 100L)\n                                     //1 frame every 10 seconds\n                                    .setFrameRate(0.1)\n                                    .setDuration(1, TimeUnit.HOURS)\n                                    .setFormat(\"ismv\"))\n                            .addArgument(\"-nostdin\")\n                            .execute();\n                });\n\n    }\n}\n</code></pre>\n<p>Vous devrez également modifier la configuration de votre application SpringBoot (fichier application.properties) pour augmenter le délai d'attente pour les requêtes asynchrones.</p>\n<pre><code class=\"language-html\">spring.mvc.async.request-timeout = 3600000\n</code></pre>\n<p>Il vous suffit d'appeler votre API sur la page web :</p>\n<pre><code class=\"language-html\">&#x3C;div class=\"video\">\n  &#x3C;video width=\"100%\" height=\"auto\" controls autoplay muted loop *ngIf=\"event?.video\">\n    &#x3C;source src=\"http://localhost:8080/video/live.mp4\"\n            type=\"video/mp4\">\n    Sorry, your browser doesn't support embedded videos.\n  &#x3C;/video>\n&#x3C;/div>\n</code></pre>\n<p>Et voici le résultat :</p>\n<p><img src=\"https://giboow.fr/static/images/post/proxy-transcoder-ffmpeg/result-ffmpeg-transcoder.png\" alt=\"Final result\"></p>\n<p>Facile non?</p>\n","author":"giboow","title":"Comment construire un transcodeur vidéo avec SpringBoot et FFMPEG !","date":"2021-10-12","keywords":["Video","Transcoder","SpringBoot"],"image":"/static/images/post/proxy-transcoder-ffmpeg/main.jpg"}},"__N_SSG":true}